# LLM Provider Configuration
llm:
  provider: "openrouter"  # openrouter | anthropic | openai
  model: "openai/gpt-5.2"
  temperature: 0.2  # Lower = more deterministic (0.0 = most deterministic)
  seed: 42  # Random seed for reproducible outputs
  max_tokens: 128000  # Max output tokens (gpt-5.2: 128K)
  max_context_tokens: 400000  # Context window (input+output, gpt-5.2: 400K)
  reasoning_enabled: true  # Enable reasoning for thinking models
  reasoning_max_tokens: 64000  # Tokens allocated for reasoning (optional)
  # Web search for real-time documentation lookup (OpenRouter only)
  web_search_enabled: true  # Enable real-time document search
  web_search_max_results: 3  # Number of search results (1-10, default: 5)


# Data Provider Configuration
data:
  provider: "supabase"  # supabase (Supabase DB + YFinance fallback) | yfinance | mock
  is_paper: true  # Use paper trading mode (when live trading API key unavailable)
  fallback_providers: ["yfinance", "mock"]  # Fallback to yfinance if not in Supabase
  cache_ttl_seconds: 300

# Code Execution Configuration
execution:
  provider: "docker"  # docker | local
  fallback_to_local: true  # Fallback to local if Docker fails
  docker_image: "backtest-runner:latest"  # Custom image with backtesting dependencies
  docker_socket_url: null  # Auto-detect (WSL2: /var/run/docker.sock, macOS: ~/.docker/run/docker.sock)
  # docker_socket_url: "unix:///Users/heesukim/.docker/run/docker.sock"  # macOS Docker Desktop socket
  timeout: 300
  memory_limit: "2g"
  allowed_modules:
    - pandas
    - numpy
